# Nginx集群


## 最佳实践

## 考察问
- `()`®是一个基于Nginx的高性能Web平台, 使用Lua语言.
- Nginx集群缓存方案:
    - 本地缓存: `()`的功能，可以在nginx的多个worker之间共享数据，实现缓存功能。
    - redis缓存
    - 反向代理Tomcat: nginx提供了基于`()`做负载均衡的算法, 据请求路径做`()`运算，把得到的数值对tomcat服务的`()`取余，余数是几，就访问第几个服务，实现负载均衡。



## 考察点

- `OpenResty`®是一个基于Nginx的高性能Web平台, 使用Lua语言.
- Nginx集群缓存方案:
    - 本地缓存: `shard dict`的功能，可以在nginx的多个worker之间共享数据，实现缓存功能。
    - redis缓存
    - 反向代理Tomcat: nginx提供了基于`请求路径`做负载均衡的算法, 据请求路径做`hash`运算，把得到的数值对tomcat服务的`数量`取余，余数是几，就访问第几个服务，实现负载均衡。

## 安装OpenResty

Nginx本地缓存需要Nginx编程，Nginx编程使用OpenResty。

OpenResty®是一个基于`Nginx`的高性能`Web平台`，用于方便地搭建能够处理超高并发、扩展性极高的动态Web应用、Web服务和动态网关。具备下列特点：

- 具备Nginx的完整功能
- 基于`Lua`语言进行扩展，集成了大量精良的Lua库、第三方模块. 允许使用Lua自定义业务逻辑、自定义库


## 本地缓存API

OpenResty为Nginx提供了`shard dict`的功能，可以在nginx的多个worker之间共享数据，实现缓存功能。


## redis缓存

[text](../../8数据工程/5redis/5_0redis缓存🔴🟨💛.md)

## 反向代理Tomcat

请求地址是localhost，端口是80，就被windows上安装的Nginx服务给接收到了。然后代理给了OpenResty集群：我们需要在OpenResty中编写业务，查询商品数据并返回到浏览器。

### 基于ID负载均衡

tomcat一定是集群模式：因此，OpenResty需要对tomcat集群做负载均衡。

而默认的负载均衡规则是轮询模式，当我们查询/item/10001时：

- 第一次会访问8081端口的tomcat服务，在该服务内部就形成了JVM进程缓存
- 第二次会访问8082端口的tomcat服务，该服务内部没有JVM缓存（因为JVM缓存无法共享），会查询数据库
- ...

因为轮询的原因，第一次查询8081形成的JVM缓存并未生效，直到下一次再次访问到8081时才可以生效，缓存命中率太低了。

怎么办？如果能让同一个商品，每次查询时都访问同一个tomcat服务，那么JVM缓存就一定能生效了。也就是说，我们需要根据商品id做负载均衡，而不是轮询。

### 原理

nginx提供了基于请求路径做负载均衡的算法：

nginx根据请求路径做hash运算，把得到的数值对tomcat服务的数量取余，余数是几，就访问第几个服务，实现负载均衡。

例如：

- 我们的请求路径是 /item/10001
- tomcat总数为2台（8081、8082）
- 对请求路径/item/1001做hash运算求余的结果为1
- 则访问第一个tomcat服务，也就是8081

只要id不变，每次hash运算结果也不会变，那就可以保证同一个商品，一直访问同一个tomcat服务，确保JVM缓存生效。
