# 数据分析模型_回归分析
考纲: 

- 一元线性回归:

    - 领会
        - 相关分析散点图的绘制与作用
        - 相关系数的计算公式
    - 熟知
        - 相关分析的概念与特点
        - 相关关系与函数关系的区别与联系
        - 相关关系的种类及意义
        - 一元线性回归系数的最小二乘估计
        - 一元线性回归模型的检验
    - 应用
        - 计算相关系数与回归系数
        - 回归分析与相关分析的区别与联系

- 多元线性回归:

    - 领会
        - 多元线性回归的原理
    - 熟知
        - 使用最小二乘法计算多元回归模型的结果
        - 明确线性回归的 6 个经典假设
        - 明确违反上述假设后出现的问题以及解决方法
        - 明晰横截面和时间序列数据在回归建模上的差异
        - 模型评估、模型检验、系数检验
    - 应用
        - 结合业务构建回归模型并且解释回归系数
        - 根据业务场景与变量分布情况进行函数转换
        - 解释变量为分类变量时的处理方法

分值: 
- d.一元线性回归分析（占比 10%）
- b.多元回归分析法
- 　　　多元线性回归（占比 10%）


## 回归基本概念

- 🟢(多选题)在散点图中所有的样本点都在一条直线上，那么解释变量和被解释变量之间的相关系数可能是？   
    A、-1  
    B、-2  
    C、1  
    D、2

    正确答案：AC


- 🟢(单选题)一元线性回归方程y=a+bx中，b表示（）  
    A、自变量x每增加一个单位，因变量y增加的数量  
    B、自变量x每增加一个单位，因变量y平均增加或减少的数量  
    C、自变量X每减少一个单位，因变量y减少的数量  
    D、自变量x每减少一个单位，因变量y增加的数量

    正确答案：B

- 🔴(单选题)变量x与y的样本点(x1,y1),,(x1,y1)拟合得到的线性回归直线为m,则下列说法正确的是？  
    A、x与y的相关系数介于0-1之间  
    B、🔴x与y的相关系数为直线m的斜率  
    C、直线m过点(x,y)  
    D、以上均不正确

    正确答案：C,解析：相关系数的取值范围是[1,1故A错；相关系数与直线的斜率无关，直线斜率应为回归方程中y=bx+a中b的值，故B错：


## 考点: 相关性分析

- 🟢(单选题)关于相关分析中应注意的问题，下面说法错误的是？  
    A、两变量间有线性关系存在，不一定有因果关系  
    B、如果两变量间的相关系数为0，则说明二者独立  
    C、相关分析可以通过绘制散点图来观视察  
    D、相关分析两变量的顶序可互换

    答案: B


## 考点: 线性回归模型的经典假设

- 内容:
    - 因变量$y$与自变量$x$之间具有线性关系。
    - 误差项$\epsilon$是一个服从正态分布的随机变量且独立，即$\epsilon \sim N(0,\sigma^2)$
        - 误差项$\epsilon$是一个期望值为0的随机变量，即$E(\epsilon)=0$。
        - 对于所有的$x$值，$\epsilon$的方差$\sigma^2$都相同。
        - 随机项序列不相关  
    - 不相关:
        - 解释变量与随机项不相关
        - 解释变量之间不完全相关(多元线性回归中，自变量之间不能有强共线性, 或自变量不存在共线性)
        - 随即项之间不相关
- 题目: 
    - 🔴(单选题)线性回归模型的经典假设不包含()。  
        A、🔴对于固定的自变量，因变量呈正态分布  
        B、扰动项之间相关独立，不存在时间序列之类的关系  
        C、🔴因变量与自变量之间线性相关  
        D、因变量的方差随自变量的不同而变化

        答案:D 

    - 🔴(多选题)线性回归分析的前提假设包括()。  
        A、🔴解释变量之间不完全相关  
        B、随机项满足正态分布  
        C、解释变量与随机项不相关  
        D、随机项序列不相关  

        答案:ABCD 


    - 🔴(多选题)以下关于线性回归模型的经典假设，描述正确的是（）。  
        A、自变量与因变量必须有线性关系  
        B、正交假定扰动项与自变量不相关，期望值为0  
        C、扰动项之间相互独立目服从方差相等的同一个正态分布  
        D、多元线性回归中，自变量之间不能有强共线性
        
        正确答案：B,C,D,当自变量与因变量是非线性关系时，可以使用一些方法将因变量或自变量做变换，使得变换后的因变量与自变量产生线性关系，因此A不正确，BCD是正确的。


    - 🔴(单选题)多元线性回归模型的古典假设不包括？  
        A、恒定均值假定  
        B、残差同方差和无自相关假定  
        C、随机扰动项与解释变量不相关假定  
        D、无多重共线性假定

        正确答案：A,解析：A应为残差的均值恒定为零


    - 🔴(多选题)在线性回归模型y=bX+a+e中，e的基本假设是
        A、是一个很小的常数
        B、是个满足正态分布的随机变量
        C、期望为0
        D、不是随机变量

        正确答案：BC,回答正确



    - 🔴(单选题)关于线性回归模型假设说法不正确的是？  
        A、因变量和自变量要有因果关系  
        B、残差均值为0  
        C、残差服从正态分布  
        D、自变量不存在共线性

        正确答案：A


    - 🟢(单选题)线性回归模型中误差项的数学期望为  
        A、0  
        B、1  
        C、2  
        D、3

        答案: A

    - 🔴(单选题)根据模型假设，线性回归模型中误差项的方差为  
        A、常数  
        B、函数  
        C、随机变量  
        D、以上都不是

        答案: B

## 考点: 线性回归模型公式

- 🟢(单选题)线性回归模型y=a+bx+e,中的e是  
    A、因变量  
    B、自变量  
    C、误差项  
    D、回归系数

    答案: C


- 🟢(多选题)使用statsmodels建立一元线性回归模型时，若采用公式法(formula方法)建模，会用到下列哪些步骤（）  
    A、`formula ="Y~X"`  
    B、`m.ols(formula,data)`  
    C、`m.fit()`  
    D、`m.summary()`

    正确答案：A,B,C,D


- 🟢(单选题)销量(Y,台)与单位产品价格(X,元台)之间的回归方程为Y=356-1.5X,这说明  
    A、价格每增勖加一元，销量增加356台  
    B、价格每增勖加一元，销量增加1.5台  
    C、价格每增勖们一元，销量平均增勖1356台  
    D、价格每增勖1一元，销量平均减心少1.5台

    答案: D



- 🔴(多选题)在线性回归分析中，下列描述合理的是？
    A、因变量可以是连续的也可以是离散的
    B、自变量可以是连续的也可以是离散的
    C、样本点与模型预测值之间的差值叫做残差，残差的绝对值越小，说明模型越准确
    D、🔴自变量和因变量是对等关系

    正确答案：BC,解析：线性回归模型中，因变量必须是连续型变量，自变量可以是连续型变量也可以是离散型变量；因变量与自变量之间是非对等关系。


## 考点: 线性回归模型基本概念

- 🟢(单选题)多元回归模型的“线性”是指对()而言是线性的。  
    A、解释变量  
    B、被解释变量  
    C、回归参数  
    D、剩余项

    答案:C 

- 🟢(单选题)下列关于多元回归方程中的变量说法不正确的是( )。  
    A、典型的非线性变换包括自然对数、平方根、倒数和平方  
    B、交互变量表示两个变量之间存在交互作用，在方程中常体现为两者之和
    C、创建虚拟/哑变量(Dummy variables)可以将定性的变量量化
    D、如果一个定性变量中有m种互斥的属性类型，则在模型中需要引入m-1个虚拟/哑变量

    答案:B 
    解析:本题考查多元线性回归模型的相关知识。交互变量表示两个变量
    之间存在交互作用，在方程中常体现为两者相乘而不是求和，因此B选项表述错误，本题应选B。


- 🔴(单选题)假设在多元线性回归中，我们有了因变量Y和自变量$X1,X2..,X(p-1)$的组观测值，则下列说法正确的是  
    A、最小二乘法只适用于一元线性回归而不适用于多元线性回归  
    B、用最小二雨法求解得到的多元线性回归的回归超平面，可能有一个超平面也可能有无穷多个超平面  
    C、在系数估计的所有无偏估计中，最小二乘估计并不是唯一的最小方差估计  
    D、对于个随机误差项，一般假设其均值为0，方差为1，且互不相关

    正确答案：B

    解析：A最小二乘同样适用于多元线性回归B.当白变量矩阵列满秩，可得一个超平面。当自变量矩不满秩，可得无穷多个超平面：C在系数估计的所有无偏估计中，最小二乘估计是唯一的最小方差估计：D.随机误差项的方差只要相等即可，不要求等于1

- 🟢(单选题)关于一元线性回归的求解过程说法正确的是？  
    A、一元线性回归只需要求解出两个参数系数即可  
    B、对于新来的样例，建立好的一元线性回归模型可以做出准确的预测  
    C、一元线性回归模型的基本式是Y=Ax+e,其中A为系数，e为随机误差  
    D、一元线性回归模型的估计系数是对应真实值的有偏估计

    正确答案：A,回归模型中的估计系数是对应真实系数的无偏估计🔴




## 考点: 线性模型评估指标

- 参考: 
    - [回归模型的评估指标](../../../数学/统计学/11一元线性回归/回归模型的评估指标.md)
    - [回归模型评估](../../../数学/统计学/11一元线性回归/3回归模型评估.md)
    - [线性关系和回归系数检验](../../../数学/统计学/11一元线性回归/4线性关系和回归系数检验.md)

- 内容: 

    - R-Squared是SSR与SST的比值(要求记忆公式)
        
        $$
        R^2 = \frac{SSR}{SST}= 1-\frac{SSE}{SST}
        $$

    - Adjusted R-Squared, 如果模型中增加一个自变量，即使这个自变量在统计上并不显著，$R^2$也会变大。$R_{\alpha}$同时考虑了样本量$n$和模型中自变量的个数$k$的影响(不要求公式)

        $$
        R_{\alpha}^2 = 1 - (1-R^2)\frac{n-1}{n-k-1}
        $$

    - F Statistics(要求记忆公式🔴)

        $$
        F = \frac{SSR/k}{SSE/(n-k-1)} \sim F(k,n-k-1)
        $$

    - MSE，均方误差，Mean squared error，预测值与真实值的绝对平方误差的平均值(要求记忆公式🔴)

        $$
        MSE = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2
        $$

    - MAE，平均绝对误差，Mean absolute error，预测值与真实值的绝对误差的平均值(要求记忆公式🔴)

        $$
        MAE = \frac{1}{n} \sum_{i=1}^n |y_i - \hat{y}_i|
        $$

    - MAPE，平均绝对百分比误差，Mean absolute percentage error，此指标对相对误差敏感，不会因目标变量的全局缩放而改变，适合目标变量量纲差距较大的问题。(仅理解)

        $$
        MAPE = \frac{1}{n} \sum_{i=1}^n \frac{y_i - \hat{y}_i}{max(\epsilon, |y_i|)}
        $$


## 考点: F统计量检验: 相关性检验


- 内容: 

    F统计量的构造是以回归平方和(SSR)和残差平方和(SSE)为基础的。
    - 将SSR除以其相应的自由度(SSR的自由度是自变量的个数$k$,一元线性回归中自由度为1)的结果称为均方回归，记为MSR;
    - 将SSE除以其相应的自由度(SSE的自由度为$n-k-1$，一元线性回归中自由度为$n-2$)的结果称为均方残差，记为MSE。

    $$
    F = \frac{SSR/k}{SSE/(n-k-1)} = \frac{MSR}{MSE} \sim F(k, n-k-1)
    $$

    

- 题目: 

    - 🟢(单选题)线性回归分析中，回归方程的检验是？
        A、t检验
        B、卡方检验
        C、F检验
        D、正态检验

        答案: C

    - 🟢(单选题)在多元线性回归问题中，对于模型整体检验的原假设是( )。  
        A、回归系数全为0   
        B、回归系数不全为0   
        C、回归系数全为1  
        D、回归系数不全为1 

        答案:A, F统计量检验


    - 🔴(单选题)含有p个变量的多元回归模型，样本量为$n$，该模型的回归平方和、残差平方和的自由度分别为()。  
        A、$p、n-p$  
        B、$n-p、p$  
        C、$p、n-p-1$  
        D、$n-p-1、p$ 

        答案:C, 考察F统计量的公式



## t统计量检验: 系数检验

- 参考
    [4线性关系和回归系数检验](../../5_1统计学/统计学/11一元线性回归/4线性关系和回归系数检验.md)

- 内容:

1. 第1步: 提出检验
    $$
    H_0: \beta_1 = 0 ; H_1: \beta_1 \neq 0
    $$

2. 第2步: 计算检验统计量
    $$
    t = \frac{\hat{\beta}_1}{S_{\hat{\beta}_1}}
    $$

3. 第3步：作出决策。确定显著性水平$\alpha$,并根据自由度$df=n-2$查$t$分布表，找到相应的临界值$t_{\alpha/2}$。
    - 若$|t|>t_{\alpha/2}$,则拒绝$H_0$,回归系数等于0的可能性小于$\alpha$,表明自变量$x$对因变量$y$的影响是显著的，换言之，两个变量之间存在显著的线性关系；
    - 若$|t|<t_{\alpha/2}$,则不拒绝$H_0$,没有证据表明$x$对$y$的影响显著，或者说，二者之间尚不存在显著的线性关系。


- 题目: 

    - 🟢(单选题)线性回归分析中，回归系数的检验是？  
        A、t检验  
        B、卡方检验  
        C、F检验  
        D、正态检验

        正确答案：A

    - 🟢(单选题)现在通过参数估计得到一个一元线性回归模型为y=3x+4,在回归系数检验中下列说法错误的是（）  
        A、检验统计量是t统计量  
        B、原假设是$\beta_1=3$  
        C、若柜绝原假设，就认为自变量与因变量存在显著的线性关系  
        D、可以用P值与显著性水平比较结果判断是否拒绝原假设

        答案:B

    - 🟢(单选题)在进行线性回归系数的假设检验时，以下哪项描述是正确的？  
        A、在多元线性回归中，检验统计量F用于检验单个回归系数是否为0.  
        B、在简单线性回归中，系数估计值的检验统计量服从自由度为的分布。  
        C、原假设认为在简单线性回归中回归系数$1不等于0.  
        D、在多元线性回归中，检验统计量F用于检验是否所有回归系数同时为0.

        正确答案：D,在线性回归分析中，对回归系数的检验是一个关键步骤。在简单线性回归中，对回归系数$\beta_1$的假设检验是通过检验统计量进行的，其服从自由度为-2的t分布(其中n是样本大小)。该统计量用于检验$\beta_1$是否显菩不等于O.选项B是错误的，因为它提到了自由度为n的t分布，而不是自由度为n-2。选项C是错误的，因为原假设是β1等于0。选项A也是错误的，因为F统计量是用来同时检验多元线性回归中所有回归系数是否全部为O的。因此，选项D是正确的，它描述了在多元线性回归中使用F统计量进行全模型的假设检验。


## 考点: 判定系数

- 参考

    - [一元回归模型评估](../../5_1统计学/统计学/11一元线性回归/3回归模型评估.md)
    - [多元回归模型评估](../../5_1统计学/统计学/12多元线性回归/2回归模型评估.md)

- 内容

    $$
    R^2 = \frac{SSR}{SST} = \frac{\sum(\hat{y}_i - \overline{y})^2}{\sum(y_i - \overline{y})^2} = 1- \frac{\sum(y_i - \hat{y}_i)^2}{\sum(y_i - \overline{y})^2}
    $$

- 题目:

    - 🟢(单选题)判定系数$R^2$是指( )。  
        A、残差平方和占总离差平方和的比重  
        B、总离差平方和占回归平方和的比重  
        C、回归平方和占总离差平方和的比重  
        D、回归平方和占残差平方和的比重

        答案:C 

    - 🟢(单选题)在评价多元线性回归模型拟合程度时，主要根据( )的数值。  
        A、修正R2   
        B、R2   
        C、SSE   
        D、SSR   

        答案:B 

    - 🔴(单选题)下列哪些指标不适合用来评估线性回归模型？  
        A、LIFT  
        B、Adjusted R-Squared  
        C、F Statistics  
        D、MAPE

        正确答案：A


## 残差分析
- 内容:
  
    对残差序列的假设(同扰动项随即项的假设)包括：
    - 不相关
    - 正态性
    - 同方差

- 题目: 
    - 🔴(单选题)在线性回归模型的经典假设中，以下哪一项不是残差分析时需要考虑的条件？  
        A、残差不能和自变量相关  
        B、残差必须独立且同分布  
        C、自变量之间不能有相关性  
        D、残差方差应具有齐性（即方差恒定）

        正确答宾：C, 解析：自变量之间不能有强共线性，又称多重共线性。如果多元线性回归中存在多重共线性问题，那么会使回归系数、截距系数的估计值非常不稳定。可这不属于残差分析时需要考虑的内容。


    - 🔴(多选题)在线性回归的高斯马尔科夫假设中，以下属于对残差的假设的有（）  
        A、残差序列不相关  
        B、残差序列方差为1  
        C、残差序列为正态分布  
        D、残差序列方差相同

        正确答案：ACD,在高斯马尔科夫假设中，对残差序列的假设包括：不相关、正态性和同方差，对应ACD选项，残差序列的方差不一定为1。

    - 🟢(单选题)残差平方和是指( )。  
        A、被解释变量观测值与估计值的比例  
        B、被解释变量回归估计值总变差的大小  
        C、被解释变量观测值总变差的大小  
        D、被解释变量观测值总变差中未被列入模型的解释变量

        答案:D


    - 🟢(单选题)下列关于线性回归分析中的残差说法正确的是()。  
        A、残差均值总是为零  
        B、残差均值总是小于零  
        C、残差均值总是大于零  
        D、以上说法都不对

        答案:A, 残差平方和是关于参数的函数，为了求残差极小值，令残关于参数的偏导数为零，会得到残差和为零，即残差均值为零

    - 🟢(单选题)在多元线性回归分析中，残差平方和反映了( )。  
        A、因变量观测值总变差的大小  
        B、因变量回归估计值总变差的大小  
        C、因变量观测值与估计值之间的总变差  
        D、关于Y对X的边际变化

        答案:C 


    - 🟢(多选题)在利用残差图进行回归统计诊断时，哪种情况说明模型不满足方差齐性的假设？(这里残差图的横坐标是因变量的拟合值，纵坐标是学生化内残差)  
        A、残差图中残差随着因变量拟合值的增大而减小  
        B、残差图中残差随着因变量拟合值的增大而增大  
        C、残差图中的所有点没有呈现任何有规律的趋势  
        D、残差之间具有一定相关性

        正确答案：A,B, 解析:C选项的情况说明残差的均值不是常数0，但这与方差齐性无关，故不选。D选项无法从残差图看出，也与方差齐性无关。故选AB

    - 🔴(单选题)在回归模型中，关于残差图的绘制方法正确的是（）  
        A、一元回归中，横坐标为预测值，纵坐标为残差  
        B、一元回归中，横坐标为残差，纵坐标为预值  
        C、多元回归中，横坐标为预测值，纵坐标为残差  
        D、多元回归中，横坐标为残差，纵坐标为预值

        正确答案：C,

    - 🔴(多选题)在利用残差图进行回归统计诊断时，用什么判断模型满足独立同分布(这里残差图的横坐标是因变量的拟合值，纵坐标是学生化残差)？  
        A、残差图中的所有点都以均值0为中心随机分布在一条水平带中间  
        B、残差图中的残差随着因变量拟合值的增大而增大  
        C、残差图中的所有点没有呈现任何有规律的趋势  
        D、残差之间具有一定相关性

        答案:AC 
        解析:本题考查利用残差图进行回归统计诊断的方法。选项A残差图中的所有点都以均值0为中心随机分布在一条水平带中间是正确的，表明这是满足独立同分布的。选项C残差图中的所有点没有呈现任何有规律的趋势，说明是互相独立的。其余选项表述均错误，因此本题选AC。


## 考点: 多重共线性

- 参考:

    [多重共线性(multicollinearity)](../../5_1统计学/统计学/12多元线性回归/4多重共线性(multicollinearity).md)


- 题目: 

    - 🔴(单选题)如果回归分析中存在多重共线性，则下列说法错误的是()。  
        A、所求出的参数的含义将变得不合理  
        B、不会影响模型中回归参数的标准差  
        C、可用岭回归或Lasso回归降低多重共线性对回归结果的影响  
        D、🔴存在多重共线性的变量所求参数将变得不显著

        答案:B 


    - 🟢(单选题)在多元线性回归中，遇到多重共线性问题时可以( )。
        A、取对数
        B、平方
        C、删除异常值
        D、逐步回归

        答案:D 

    - 🟢(单选题)在多元线性回归模型中，若某个解释变量对其余解释变量的判定系数接近1，则表明模型中存在( )。  
        A、异方差性  
        B、序列相关  
        C、多重共线性  
        D、高拟合优度

        答案:C 


    - 🟢(单选题)如果方差膨胀因子VIF=15,则认为()问题是严重的。  
        A、异方差问题  
        B、序列相关问题  
        C、解释变量与随机项的相关性  
        D、多重共线性

        答案:D 


    - 🔴(单选题)在处理多重共线性的问题时，如果不希望更换原有的最小二乘线性回归模型，以下哪个方法不推荐使用？  
        A、提前筛选变量，结合变量聚类方法保留最优变量  
        B、子集选择，如逐步回归法和最优子集法  
        C、收缩方法，如岭回归和Lasso回归  
        D、维数宿减，如主成分回归(PCR)和偏最小二乘回归(PLS)

        正确答宾：C,收缩方法，特别是怜回归和Lasso回归，虽然可以处理多重共线性问题，但它们涉及新的回归模型，不属于最小二乘线性回归的范畴。因此，在坚持使用最小二乘法时，不推荐使用收缩方法。



    - 🟢(多选题)在使用statsmodels中的variance inflation factor库检验数据data(包含列Y、X1、X2、X3)是否存在多重共线性问题时，需要进行的处理包括（）  
        A、`data.drop(['X1','X2',X3'].axis=1)`  
        B、`data.drop([Y],axis=1)`  
        C、`data['A]=1`  
        D、`data['A]=0`

        正确答宾：B,C,statsmodels中的variance inflation factorj库检验共线性问题时，没有为模型添加截距项，也无法识别正真的因变量，故需要手动去除因变量并且添加截距项。

    - 🟢(多选题)在建立多元线性回归模型时，若出现了多重共线性问题，则可以使用下列哪些方法进行缓解（）  
        A、使用逐步回归  
        B、删除自变量  
        C、计算VIF值  
        D、删除因变量

        正确答案：AB,在缓解多重共线性问题时，可以使用逐步回归筛选最优的自变量组合，也可以册除共线性高的自变量，故选AB.F值是识别是否出现共线性问题的指标，不可以缓解共线性问题，共线性问题是指自变量之间出现了较高的相关性，与因变量无关。





    - 🟢(单选题)如果回归模型中存在多重共线性，以下说法不能解决这一问题的是？
        A、对因变量取对数
        B、使用主成分分析进行变量降维
        C、通过计算方差膨胀因子来检查共线性程度，并采取相应措施
        D、删除相关变量可能会有信息损失，我们可以不删除相关变量，而使用一些正则化方法来解决多重共线性问题

        正确答案：A


    - 🔴放弃超纲题目(单选题)关于岭回归和Lasso回归描述错误的是：  
        A、岭回归的扰动项越大，模型越不容易受到共线性的影响  
        B、岭回归的扰动项挤占了w中由原始的特征矩阵贡献的空间  
        C、相比Lasso,怜回归中自变量系数会很快衰减，但很难归为零  
        D、Lasso可以解决特征之间"共线性的问题

        正确答案：D,解析：D选项不严谨，Lasso,只是缓解了由于共线性导致的估计误差的问题，而不是解决共线性，故错误

    - 🔴(单选题)以下哪种方法不可以解决回归模型的多重共线性问题？  
        A、KNN  
        B、逐步回归  
        C、正则  
        D、🔴偏最小二乘

        正确答案：A,解析：KNN是分类算法，与多重共线性无关，故A错

## 参数的最小二乘估计
- 参考: 

    [参数的最小二乘估计](../../5_1统计学/统计学/11一元线性回归/2一元线性回归.md#参数的最小二乘估计)

- 题目:
    - 🟢(单选题)在回归分析，回归系数的估计方法是()。  
        A、最小二乘法  
        B、最大二乘法  
        C、一致估计法  
        D、有效估计法

        答案:A 


## 逐步回归

- 参考:

    [变量选择与逐步回归](../../5_1统计学/统计学/12多元线性回归/6变量选择与逐步回归.md)


- 题目: 
    - 🟢(多选题)在多元线性回归模型的自变量选择方法中，关于向后回归法和逐步回归法的描述，以下哪些是正确的？
        A、向后回归法开始时包含所有自变量，并逐步易剔别除每个不显著的变量
        B、逐步回归法结合了向前回归法和向后回归法，可以在模型中添加或删除变量。
        C、向后回归法需要样本量大于自变量的个数。
        D、逐步回归法在添加新变量时不会重新评估模型中已有变量的显菩性。

        正确答案：A,B,C




## 考点: 线性回归与矩阵

- 🔴(单选题)在多元线性回归模型中自变量的系数矩阵X为列满秩，则表明矩X的列向量之间是什么关系？  
    A、线性相关  
    B、存在多重共线性  
    C、线性无关  
    D、无法判断

    正确答案：C

    解析：系数柜阵每一列对应一个自变量，列满秩意味着自变量X之间线性无关，



- 🔴(单选题)多元线性回归的正规方程组中系数柜阵X'X的阶数等于？(p个变量，n个观测值)  
    A、n  
    B、p-1  
    C、p  
    D、n-1

    正确答室：C解析：系数矩眸X的列数即为自变量的个数，一股用P表示。则XX是一个PP的矩阵，阶数为P.X'为X的
    转置）




## 考点: 其他



- 🔴(单选题)关于忽略自相关可以带来什么问题描述错误的是？  
    A、均方误差可能严重低估误差项的方差  
    B、可能导致高估检验统计量值，致使本不显著的变量变得显著了  
    C、参数估计值的最小方差无偏性不再成立  
    D、参数估计值的最小方差无偏性仍成位

    答案: D

- 🟢(单选题)在回归模型中，下列那一项在权衡欠拟合(under-.-fitting)和过拟合(over-fitting)中影响最大？  
    A、多项式阶数  
    B、更新回归数w时，使用的是协方差矩车求逆还是梯度下降  
    C、使用常数项  
    D、以上都不是

    正确答案：A


- 🔴(单选题)在建立回归模型的过程中，下面说法不正确的是？  
    A、方差膨胀系数检验以确保解释变量之间无强线性相关  
    B、异方差检验和D-W检验以确保扰动项独立目同分布  
    C、QQ检验以确保扰动项服从二项分布  
    D、选择合适的回归方法和变量以及变量如何放入模型

    正确答宾：C, QQ检验以确保扰动项服从正态分布



### 考点: 实操

- 🟢(单选题)假设已经导入了相关的库，在使用statsmodelsi建立线性回归模型时，以下选项中，正确指出了建模步骤中存在问题的是（）  
    ```
    fomular=Y~X1+X2+X3'  
    model ols(fomular,data=data)  
    model.summary（）  
    ```
    A、公式的书写方式错误  
    B、ols库使用错误  
    C、缺少模型的拟合步骤  
    D、模型结果输出方式错误

    正确答案：C

- 🔴(单选题)使用因变量Y和自变量X1、X2、X3建立一个多元线性回归模型后，输出模型的残差图的方法正确的是()
    
    A、`plt.scatter(m.predict(data),m.resid)`  
    B、`plt.scatter(m.resid,X1)`  
    C、`plt.scatter(Y,m.resid)`  
    D、`plt.scatter(m.resid,Y)`

    正确答案：A


- 🟢(单选题)将多分类变量纳入多元线性回归模型的建立时，需要将其进行哑变量变换，下面哪个选项可以将名为df的DataFrame中的分类变量A进行哑变量编码？（）  
    A、`pd.Series(df['A])`  
    B、`pd.concat(df['A])`  
    C、`pd.value_counts(df'A])`  
    D、`pd.get_dummies(df'A])`

    正确答案：D



- 🟢(单选题)关于高维数据在模型建立中的处理，以下描述正确的是：  
    A、在分类模型中通常不需要进行变量选择和降维，因为算法可以处理成千上万个变量。  
    B、聚类模型中别除不相关变星主要依赖于算法而不是分析师的经验和维度分析。  
    C、特征选择指的是从相关性较强的变量中提取代表性的变量，还可以做多项式旋转会增加变量  
    D、在数据挖掘的实践中，最住实践是建立一个包含所有变量的大模型来处理不同情况。

    正确答案：C,特征选择是从相关性较强的变量中桃选代表性的变量进行建模，选项A忽视了变量选择和降维的重要性，选项B措误地指出聚类模型完全依赖算法，而实际上聚类模型在别除不相关变量时依赖分析师的经验和维度分析。选项D与最佳实践相反，因为最佳实践建议是针对不同情况建立不同的模型，而不是一个包含所有变量的大模型。



## 考点: 回归分析大题


- 内容:

    - `No.Observations`: 样本容量
    - `Df Residuals`: `样本容量`减去参与`估计的参数个数`
    - `Df Model`: 用到的`解释变量的个数`(不是参数个数)
    - `R-squared/Adj.R-squared`: 决定系数与修正决定系数
    - `F-statistic/Prob(F-statistic)`: 方差分析的结果


- 题目: 
    - 建立多元回归方程：

        `avg_exp_In ~ Income_In + Selfempl + high_avg + gender + Age + edu_class_小学以下 + edu_class_中学 + edu_class_研究生`


    - 字段含义

        字段名|字段含义
        --|--
        avg_exp_In|月均信用卡支出（元）的自然对数
        gender|性别(男=1，女=0)
        Age|年龄
        Income_In|年收入（万元）的自然对数
        Selfempl|是否自谋职业(1=yes,0=no)
        high_avg|高出当地平均收入
        edu_class|教育等级：小学及以下开通=0，中学=1，本科=2，研究生=3

    - 模型基本信息

        - Dep.Variable: avg_exp_In
        - Model: OLS
        - Method: Least Squares
        - Date: Thu,14 Jan 2021
        - Time: 09:08:52
        - No.Observations: 70
        - Df Residuals: 口
        - Df Model: 8
        - Covariance Type: nonrobust
        - R-squared: 0.913
        - Adj.R-squared: 0.901
        - F-statistic: 79.86
        - Prob(F-statistic): 2.10e-29
        - Log-Likelihood: 38.537
        - AIC: -59.07
        - BIC: -38.84

    - 模型回归系数表

        --|coef|std err|t |P>\|t\||[0.025|0.975]
        --|--|--|--|--|--|--
        Intercept|5.1784|0.175|29.645|0.000|4.829|5.528
        Income_In|0.9388|0.086|10.953|0.000|0.767|1.110
        Selfempl |-0.3275|0.116|-2.822|0.006|-0.560|-0.095
        high_avg|-0.1150|0.043|-2.652|0.010|-0.202|-0.028
        gender|-0.4427|0.060|-7.424|0.000|-0.562|-0.323
        Age|-0.0012|0.003|-0.435|0.665|-0.007|0.004
        edu_class_小学以下|-1.2642|0.116|-10.930|0.000|-1.496|-1.033
        edu_class_中学|-0.3322|0.047|-7.117|0.000|-0.426|-0.239
        edu_class_研究生|0.1496|0.052|2.898|0.005|0.046|0.253



    - 🟢(单选题)这个多元回归模型中，自变量对因变量的解释力度有多大？  
        A.91.3%  
        B.59.07%  
        C.91.3%  
        D.79.86%

        正确答案：A


    - 🔴(单选题)多元回归方差分析中残差平方和SSE统计量对应的自由度为？  
        A.70  
        B.62  
        C.61  
        D.69

        正确答案：C

    - 🟢(多选题)查看该回归模型的线性关系是否显著，可通过哪些或哪个指标来看？  
        A.Log-Likelihood:38.537  
        B.F-statistic:79.86  
        C.Prob (F-statistic):2.10e-29  
        D.以上皆不是

        正确答案：BC


    - 🟢(单选题)对模型的回归系数检验中，哪些或哪个系数不显著？  
        A.Age  
        B.high_avg  
        C.Intercept  
        D.Income In

        正确答案：A


    - 🔴(多选题)多重共线性是多元回归模型的一个重要的回归诊断，对于多重共线性的诊断一般使用什么指标？  
        A.AIC  
        B.BIC  
        C.IV  
        D.VIF

        正确答案：D

