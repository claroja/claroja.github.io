


## 直接调用

```python
import ollama
model = 'deepseek-r1:1.5b'

prompt = '介绍自己'

response = ollama.chat(
  model, 
  messages=[{
    'role': 'user',
    'content': prompt,
  },
])

print(response['message']['content'])
```



## 流式调用

```python

import ollama
model = 'deepseek-r1:1.5b'

prompt = '介绍自己'

ollama_response = ollama.chat(
    model,
    stream=True,
    messages=[
        {
            'role': 'user',
            'content': prompt,
        },
    ]
)

for chunk in ollama_response:
    print(chunk['message']['content'], end='', flush=True)

```


## 上下文持续对话
```python
import ollama
model = 'deepseek-r1:1.5b'

chat_messages = []

def create_message(content, role):
    return {'role': role, 'content': content}

def chat():
    response = ollama.chat(model, stream=True, messages=chat_messages)
    assistant_message = ''
    for chunk in response:
        assistant_message += chunk['message']['content']
        print(chunk['message']['content'], end='', flush=True)
    chat_messages.append(create_message(assistant_message, 'assistant'))

def ask(message):
    chat_messages.append(create_message(message, 'user'))
    print(f'\n\n--{message}--\n\n')
    chat()

ask('中国的首都是哪里')
ask('南京距他有多远')
```



## 文本生成

```python
import ollama

response = ollama.generate(
    model='llama3',
    prompt='Once upon a time, in a faraway land,'
)
print(response['response'])
```


## 客户端

使用客户端和ollama服务端交互


```python
from ollama import Client

client = Client(host='http://your-ollama-server')
response = client.chat(model='llama3', messages=[
    {
        'role': 'user',
        'content': 'What is machine learning?',
    }
])
print(response['message']['content'])
```




## 生成SQL

```python
from ollama import Client

client = Client(host='http://localhost:11434')

prompt = 'Get the top 10 most expensive products.'
response = client.chat(model='llama3', messages=[
    {
        'role': 'system',
        'content': """Here is the database schema that the SQL query will run on:
    CREATE TABLE products (
      product_id INTEGER PRIMARY KEY,
      name VARCHAR(50),
      price DECIMAL(10,2),
      quantity INTEGER
    );
    """,
    },
    {
        'role': 'user',
        'content': prompt,
    }
])
print(response['message']['content'])
```










## 参考
1. https://lablab.ai/t/llama3-with-ollama