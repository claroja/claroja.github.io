

信息增益（Information Gain） 是一种衡量某个特征在对数据集进行划分时带来的信息量减少的指标。它常用于决策树算法中来选择分裂点，以便将数据集划分为更加纯净的子集。



信息增益（IG）表示通过使用某个特征$X$来划分数据集后，目标变量$Y$的不确定性（熵）减少的程度。信息增益的计算公式为：

$$
IG(D,X)=E(D)−E(D∣X)
$$

其中：

1. $E(D)$是划分之前数据集$D$的熵（即数据集中目标变量$Y$的不确定性）。
2. $E(D|X)$是在特征$X$的条件下，划分后的数据集的加权平均熵，表示划分后的数据集的剩余不确定性。











## 基于熵的信息增益计算

信息增益的概念基于信息熵，信息熵用于衡量数据集的不确定性或混乱程度，而信息增益衡量的是在某个特征下，数据集划分后这种不确定性减少的量。


1. 首先计算数据集在没有划分时的熵$E(D)$
2. 根据特征$X$进行划分
3. 计算划分后的加权平均熵$E(D|X)$：计算每个子集的熵，并根据每个子集的样本数对其进行加权平均：

    $$
    E(D|X) = \sum_{i=1}^n \frac{|D_i|}{|D|} E(D_i)
    $$

    其中
    1. $D_i$是按特征$X$划分后的第$i$个子集
    2. $|D_i|$是子集$D_i$中的样本数量
    3. $|D|$是原始数据集的样本数量

4. 计算信息增益
    $$
    IG(D,X)=E(D)−E(D∣X)
    $$
















## 举例说明

有如下数据, 根据天气情况判断某个人的心情:

索引|特征X|标签Y
--|--|--
1|晴|好
2|晴|好
3|晴|好
4|晴|好
5|晴|坏
6|阴|好
7|阴|好
8|阴|坏
9|阴|坏
10|阴|坏


1. 计算原始数据集的熵$E(D)$, 好占比6/10, 坏占比4/10:

    $$
    E(D) = - \left( \frac{6}{10} \log_2 \frac{6}{10} + \frac{4}{10} \log_2 \frac{4}{10} \right)
    $$

    $$
    E(D) = - \left( 0.6 \log_2 0.6 + 0.4 \log_2 0.4 \right)
    $$

    $$
    E(D) \approx 0.971
    $$

2. 根据特征$X$进行划分

    根据天气特征$X$进行划分: 
    1. $X=晴$, 包含5个样本, 其中4个类别为好, 1个类别为坏
    2. $X=阴$, 包含5个样本, 其中2个类别为好, 3个类别为坏

3. 计算划分后的加权平均熵$E(D|X)$

    1. 对于$X=晴$子集:
        $$
        E(D_1) = - \left( \frac{4}{5} \log_2 \frac{4}{5} + \frac{1}{5} \log_2 \frac{1}{5} \right) \approx 0.722
        $$

    2. 对于$X=阴$子集:

        $$
        E(D_2) = - \left( \frac{2}{5} \log_2 \frac{2}{5} + \frac{3}{5} \log_2 \frac{3}{5} \right) \approx 0.971
        $$

    3. 计算划分后所有子集的加权平均熵：
        $$
        E(D|X) = \frac{5}{10} E(D_1) + \frac{5}{10} E(D_2) = 0.8465
        $$

4. 计算信息增益$IG(D, X)$:
    $$
    IG(D, X) = E(D) - E(D|X) = 0.1245
    $$


也就是说按照特征$X$进行分类后, 熵减(不确定性减少), 信息增益增加了.



## 参考
1. https://blog.csdn.net/u013172930/article/details/142676655
2. https://blog.csdn.net/qq_39709813/article/details/106690860
3. https://tungmphung.com/information-gain-gain-ratio-and-gini-index/




























































