数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已。

当数据预处理完成后，我们需要选择有意义的特征输入机器学习的算法和模型进行训练。通常来说，从两个方面考虑来选择特征：

1. 特征是否发散：如果一个特征不发散，例如方差接近于0，也就是说样本在这个特征上基本上没有差异，这个特征对于样本的区分并没有什么用。
2. 特征与目标的相关性：这点比较显见，与目标相关性高的特征，应当优选选择。除移除低方差法外，本文介绍的其他方法均从相关性考虑。



特征选择主要有两个目的：

1. 减少特征数量、降维，使模型泛化能力更强，减少过拟合；
2. 增强对特征和特征值之间的理解。









