# 假设检验的基本问题

参数估计(parameter estimation)和假设检验(hypothesis testing)是统计推断的两个组成部分，它们都是利用样本对总体进行某种推断，但推断的角度不同。参数估计讨论的是用样本统计量估计总体参数的方法，总体参数$\mu$在估计前是未知的。而在假设检验中，则是先对$\mu$的值提出一个假设，然后利用样本信息去检验这个假设是否成立。也就是说参数估计没有对总体参数进行假设, 而假设检验对总体参数进行了假设.

## 假设问题的提出

由统计资料得知，1989年某地新生儿的平均体重为3190克，现从1990年的新生儿中随机抽取100个，测得其平均体重为3210克，问1990年的新生儿与1989年相比，体重有无显著差异？

从调查结果看，1990年新生儿的平均体重为3210克，比1989年新生儿的平均体重3190克增加了20克，但这20克的差异可能源于不同的情况。
- 一种情况是，1990年新生儿的体重与1989年相比没有什么差别，20克的差异是抽样的随机性造成的
- 另一种情况是，抽样的随机性不可能造成20克这样大的差异，1990年新生儿的体重与1989年新生儿的体重相比确实有所增加


上述问题的关键点是：20克的差异说明了什么？这个差异能不能用抽样的随机性来解释？为了回答这个问题，我们可以采取假设的方法。假设1989年和1990年新生儿的体重没有显著差异，如果用$\mu_0$表示1989年新生儿的平均体重，以$\mu$表示1990年新生儿的平均体重，我们的假设可以表示为$\mu=\mu_0$或$\mu-\mu_0=0$，现要利用1990年新生儿体重的样本信息检验上述假设是否成立。如果成立，说明这两年新生儿的体重没有显著差异；如果不成立，说明1990年新生儿的体重有了明显增加。在这里，问题是以假设的形式提出的，问题的解决方案是检验提出的假设是否成立。

## 假设的表达式


统计的语言是用一个等式或不等式表示问题的原假设。在新生儿体重这个例子中，原假设采用等式的方式，即

$$
H_0: \mu = 3190克
$$

这里$H_0$表示原假设(null hypothesis)。由于原假设($H$)的下标用$O$表示，所以有些文献中将此称为“零假设”。$\mu$是我们要检验的参数，即1990年新生儿总体体重的均值。该表达式提出的命题是，1990年的新生儿与1989年的新生儿在体重上没有什么差异。显然，3190克是1989年新生儿总体的均值，是我们感兴趣的数值。如果用$\mu_0$表示感兴趣的数值，原假设更一般的表达式为：
$$
H_0: \mu = \mu_0
$$
或
$$
H_0: \mu - \mu_0 = 0
$$

尽管原假设陈述的是两个总体的均值相等，却并不表示它是既定的事实，仅是假设而已。如果原假设不成立，就要拒绝原假设，而需要在另一个假设中作出选择，这个假设称为备择假设(alternative hypothesis)。备择假设的表达式为：

$$
H_1: \mu \neq 3190克
$$

$H_1$表示备择假设，它意味着1990年的新生儿与1989年的新生儿在体重上有明显差异。备择假设更一般的表达式为：
$$
H_1: \mu \neq \mu_0
$$
或
$$
H_1: \mu - \mu_0 \neq 0
$$

原假设与备择假设互斥，肯定原假设，意味着放弃备择假设；否定原假设，意味着接受备择假设。由于假设检验是围绕着对原假设是否成立而展开的，所以有些文献也把备择假设称为替换假设，表明当原假设不成立时的替换。

## 两类错误

假设所犯的错误有两种类型，第I类错误是原假设$H_0$。为真却被我们拒绝了，犯这种错误的概率用$\alpha$表示，所以也称$\alpha$错误($\alpha$ error)或弃真错误；第Ⅱ类错误是原假设为伪我们却没有拒绝，犯这种错误的概率用$\beta$表示，所以也称$\beta$错误($\beta$ error)或取伪错误。

- $\alpha$错误：原假设$H_0: \mu = 3190克$是正确的，但我们作出了错误的判断，认为$H_0: \mu \neq 3190克$，即在假设检验中拒绝了本来是正确的原假设，这时犯了弃真错误。
- $\beta$错误：原假设$H_0: \mu = 3190克$是错误的，但我们认为原假设$H_0: \mu = 3190克$是成立的，即在假设检验中没有拒绝本来是错误的原假设，这时犯了取伪错误。

由此看出，
- 当原假设$H_0$为真，我们却将其拒绝，犯这种错误的概率用$\alpha$表示，那么，当$H_0$为真，我们没有拒绝$H_0$,则表明作出了正确的决策，其概率自然为$1-\alpha$;
- 当原假设$H_0$为伪，我们却没有拒绝$H_0$,犯这种错误的概率用$\beta$表示，那么，当$H_0$为伪，我们拒绝$H_0$,这也是正确的决策，其概率为$1-\beta$, 正确决策和犯错误的概率可以归纳为:

项目|没有拒绝$H_0$|拒绝$H_0$
--|--|--
$H_0$为真|$1-\alpha$(正确)|$\alpha$(弃真错误)
$H_0$为伪|$\beta$(取伪错误)|$1-\beta$(正确)

> 此表可以依据[混淆矩阵(confusionMatrix)](../../../../%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/%E6%B7%B7%E6%B7%86%E7%9F%A9%E9%98%B5(confusionMatrix).md)记忆

自然，人们希望犯这两类错误的概率越小越好。但对于一定的样本量，不能同时做到犯这两类错误的概率都很小。如果减少$\alpha$错误，就会增大犯$\beta$错误的机会；若减少$\beta$错误，就会增大犯$\alpha$错误的机会。当然，使$\alpha$和$\beta$同时变小的办法也有，就是增大样本量。但样本量不可能没有限制，否则就会使抽样调查失去意义。因此，在假设检验中，就有一个对两类错误进行控制的问题。

一般来说，哪类错误所带来的后果更严重，在假设检验中就应当把哪类错误作为首要的控制目标。但在假设检验中，大家都在执行这样一个原则，即首先控制犯$\alpha$错误原则。这样做的原因主要有两点：
- 第一，大家都遵循一个统一的原则，讨论问题就比较方便。
- 第二，更主要的原因在于，从实用的观点看，原假设是什么常常是明确的，而备择假设是什么则常常是模糊的。在前面所举的新生儿体重的例子中，原假设$H_0: \mu=3190克$的数量标准十分清楚，而备择假设$H1: \mu \neq 3190克$的数量标准则比较模糊。我们不知道$\mu > 3190克$还是$\mu < 3190克$，而且大的程度也不清楚。显然，对于一个含义清楚的假设和一个含义模糊的假设，我们更愿意接受前者。正是在这个背景下，我们就更为关心如果$H_0$为真，而我们却把它拒绝了，犯这种错误的可能性有多大，而这正是$\alpha$错误所表现的内容。假设检验中犯两类错误的情况如图所示。

![](../../8%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C/1%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C%E7%9A%84%E5%9F%BA%E6%9C%AC%E9%97%AE%E9%A2%98/1.png)

如图（a）中显示，如果原假设$H_0: \mu=\mu_0$为真，样本的观察结果应当在附近，落入阴影中的概率为$\alpha$。我们是根据样本的观察结果作出判断决策，如果观察结果落入（a）中的阴影部分，我们便拒绝原假设，这时就犯了$\alpha$错误，尽管犯这个错误的概率比较小，但这种错误是不可避免的。图(b)显示，如果原假设为伪，被检验的参数$\mu > \mu_0$,那么当样本观察结果落入阴影$\beta$中时，我们还是把$\mu$看成$\mu_0$而没有拒绝，这时便犯了取伪错误，其概率为$\beta$。由图还可以看出，如果临界点沿水平方向右移，$\alpha$将变小而$\beta$将变大；如果向左移，$\alpha$将变大而$\beta$将变小。这也说明了在假设检验中$\alpha$和$\beta$此消彼长的关系。


## 假设检验的流程

1. 首先提出原假设和备择假设。在前面新生儿体重这个例子中，原假设和备择假设分别为：

$$
H_0: \mu = 3190克 \\
H_1: \mu \neq 3190克
$$


1. 接下来，同在参数估计中一样，要借助样本统计量进行统计推断，这个统计量称为检验统计量。选择哪个统计量作为检验统计量需要考虑一些因素，如，进行检验的样本量是多还是少，总体标准差$\sigma$已知还是未知。这些因素与参数估计中确定统计量所考虑的因素相同。

    计算统计量类似于分数转化过程，如同把一般得分转化为标准得分。在上例中，假定总体。已知$\sigma$且样本量大(经验说法是当$n \geq 30$时，称为大样本)，采用之统计量，计算公式为：

    $$
    z = \frac{\overline{x}-\mu_0}{\sigma/\sqrt{n}}
    $$

    将上例的数据进行转化:

    ![](../../8%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C/1%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C%E7%9A%84%E5%9F%BA%E6%9C%AC%E9%97%AE%E9%A2%98/2.png)

    在上图上方，3190.00是1989年新生儿体重的平均值，假如根据有关资料知道新生儿体重的标准差为80克，即$\sigma=80$，本例已知样本量$n=100$,根据抽样分布原理，当$\mu=3190,\sigma=80,n=100,\alpha=0.05$时得到的置信区间，3174.32为置信区间的下限，3205.68为置信区间的上限。如果原假设成立，那么95%的样本均值应当落在这个范围内。


    在上图下方，两个临界点3174.32和3205.68分别转化为之值，即$z_{\alpha/2} = \pm 1.96$, 而与总体均值3190对应的$z$值恰好为零。$z$统计量服从标准正态分布，如下图所示。

    ![](../../8%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C/1%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C%E7%9A%84%E5%9F%BA%E6%9C%AC%E9%97%AE%E9%A2%98/3.png)

    进行假设检验利用的是小概率原理，小概率原理是指发生概率很小的随机事件在一次试验中几乎不可能发生。根据这一原理可以作出是否拒绝原假设的决定。但什么样的概率才算小呢？著名的英国统计学家费希尔把小概率的标准定为0.05，虽然费希尔并没有对为什么选择0.05给出充分的解释，但人们还是沿用了这个标准，把0.05或比0.05更小的概率看成小概率。

    如果原假设成立，那么在一次试验中之统计量落入上图两侧拒绝域的概率只有0.05,这个概率是很小的。如果这个情况真的出现，我们有理由认为总体的真值不是3190克，也即拒绝原假设。接受备择假设。

    样本均值$\overline{x}=3210, \mu_0 = 3190, \sigma=80, n=100$, 可得:
    $$
    z = \frac{\overline{x}-\mu_0}{\sigma/\sqrt{n}} = \frac{3210-3190}{80/\sqrt{100}} = 2.5
    $$

3. 最后可以进行统计决策。由上图看出，计算出的之值2.5落人拒绝域，所以拒绝原假设，认为与1989年相比，1990年新生儿的体重有显著差异。

    由上图还可以看出，如果根据样本数据计算出的之值小于-1.96，同样落入拒绝域，也要拒绝原假设，将左右两边的情况结合起来，我们得到进行假设检验的决策准则：

    若$|z|<|z_{\alpha/2}|$，不拒绝$H_0$;若|z|>|z_{\alpha/2}|,拒绝$H_0$。


## 利用$P$值进行决策

前面进行检验的程序是根据检验统计量落入的区域作出是否拒绝原假设的决策。确定$\alpha$以后，拒绝域的位置也就相应确定了，其好处是进行决策的界限清晰，但缺陷是进行决策面临的风险是笼统的。

在上面的例子中，$z=2.5$，落入拒绝域，我们拒绝原假设，并知道犯弃真错误的概率（面临的风险）为0.05；如果$z=2.0$,同样落入拒绝域，我们拒绝原假设面临的风险也是0.05. 0.05是一个通用的风险概率，这是用域表示的缺陷，我们并不知道实际的概率是多少，所以可以利用$P$值进行决策。

根据随机抽样测得1990年的样本均值$\overline{x}=3210克$，与1989年的总体均值3190克相差20克，20克的差异究竟是大还是小？换句话说，如果原假设成立，即1990年新生儿体重的总体均值与1989年新生儿体重的总体均值相同，那么随机抽取出$n=100$的样本，其均值大于3210克的概率有多大呢？我们把这个概率称为$P$值，也就是当原假设为真时样本观察结果或更极端结果出现的概率。如果P值很小，说明这种情况发生的概率很小，如果这种情况出现了，根据小概率原理，我们就有理由拒绝原假设。$P$值越小，拒绝原假设的理由就越充分。
$P$值是通过计算得到的，$P$值的大小取决于三个因素：
- 一是样本数据与原假设之间的差异，在新生儿体重的例子里这个差异是20克；
- 二是样本量，这里%n=100%；
- 三是被假设参数的总体分布。

在这个例子中计算出的$P=0.01242$,这就是说，如果原假设成立，样本均值等于和大于3210克的概率只有0.01242，这是很小的，由此我们可以拒绝原假设，得到与前面$z$值检验相同的结论，如下图所示。

![](../../8%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C/1%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C%E7%9A%84%E5%9F%BA%E6%9C%AC%E9%97%AE%E9%A2%98/4.png)

$P$值的长处是它反映了观察到的实际数据与原假设之间不一致的概率值，与传统的拒绝域范围相比，$P$是一个具体的值，这样就提供了更多的信息。如果事先确定了显著性水平，如$\alpha=0.05$,则在双侧检验中，$P>0.025(\alpha /2=0.025)$不能拒绝原假设；反之，$P<0.025$则拒绝原假设。在单侧检验中，$P>0.05$不能拒绝原假设，$P<0.05$则拒绝原假设。当然，也可以直接使用$P$值进行决策，这时$P$值本身就代表了显著性水平。我们也可以使用$P$值，按照所需要的显著性水平进行判断和决策，具体做法就是将$P$值和需要的显著性水平进行比较。


## 单侧检验

之前讨论的都是双侧检验，它有两个拒绝域、两个临界值，每个拒绝域的面积为$\alpha/2$,如果原假设的命题为$\mu = \mu_0$的形式，则属于双侧检验，有

$$
H_0: \mu = 3190克 \\
H_1: \mu \neq 3190克
$$

就属于这种情况。在双侧检验中，只要$\mu \gt \mu_0$或$\mu \lt \mu$二者之中有一个成立，就可以拒绝原假设。

在另外一些情况下，我们关心的假设问题带有方向性。有两种情况：
- 一种是我们所考察的数值越大越好，如灯泡的使用寿命、轮胎行驶的里程数等；
- 另一种是数值越小越好，如废品率、生产成本等。根据人们的关注点不同，单侧检验可以有不同的方向。


### 左单侧检验

某批发商欲从厂家购进一批灯泡，根据合同规定，灯泡的使用寿命平均不得低于1000小时。已知灯泡使用寿命服从正态分布，标准差为200小时。在总体中随机抽取100个灯泡，得知样本均值为960小时，问批发商是否应该购买这批灯泡？

解这是一个单侧检验问题。显然，如果灯泡的使用寿命超过了1000小时，批发商是欢迎的，因为他用既定的价格(灯泡使用寿命为1000小时的价格)购进了更高质量的产品。因此，如果样本均值超过1000小时，他会购进这批灯泡。问题在于样本均值为960小时他是否应当购进。因为即便总体均值为1000小时，由于抽样的随机性，样本均值略小于1000小时的情况也会经常出现。在这种场合下，批发商更为关注可以容忍的下限，即当灯泡寿命低于什么水平时拒绝。于是检验的形式为：
$$
H_0: \mu \geq 1000小时 \\
H_1: \mu \le 1000小时
$$

![](../../8%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C/1%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C%E7%9A%84%E5%9F%BA%E6%9C%AC%E9%97%AE%E9%A2%98/5.png)


### 右单侧检验
某种大量生产的袋装食品按规定重量不得少于250克。今从一批该食品中随机抽取50袋，发现有6袋重量低于250克，若规定不符合标准的比例达到5%，食品就不得出厂，问该批食品能否出厂？

解显然，不符合标准的比例越小越好。在这个产品质量检验的问题中，我们比较关心次品率的上限，即不合标准的比例达到多少就要拒绝。由于采用的是产品质量抽查，即使总体不合标准的比例没有超过5%，属于合格范围，但由于抽样的随机性，样本中不合标准的比例略大于5%的情况也会经常发生。如果采用右单侧检验，确定拒绝的上限临界点，那么检验的形式可以写为：


$$
H_0: \mu \leq 5\% \\
H_1: \mu \gt 5\%
$$

![](../../8%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C/1%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C%E7%9A%84%E5%9F%BA%E6%9C%AC%E9%97%AE%E9%A2%98/6.png)





## 参考
- 统计学第8版127页