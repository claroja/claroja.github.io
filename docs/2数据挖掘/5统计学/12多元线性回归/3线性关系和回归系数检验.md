# 线性关系检验

在一元线性回归中，线性关系的检验($F$检验)与回归系数的检验($t$检验)是等价的。如，$F$检验表明不良贷款与贷款余额之间有显著的线性关系，必然也意味着回归系数不会等于0，因为只有一个自变量。

但在多元回归中，这两种检验不再等价。
- 线性关系检验主要是检验因变量与多个自变量的线性关系是否显著，在$k$个自变量中，只要有一个自变量与因变量的线性关系显著，$F$检验就能通过，但这不一定意味着每个自变量与因变量的关系都显著。
- 回归系数检验则是对每个回归系数分别进行单独的检验，主要用于检验每个自变量对因变量的影响是否显著。如果某个自变量没有通过检验，就意味着这个自变量对因变量的影响不显著。


## 线性关系检验

线性关系检验用于检验因变量$y$与$k$个自变量之间的关系是否显著，也称为总体显著性检验。

检验的具体步骤如下: 

第1步：提出假设

$$
H_0: \beta_1=\beta_2=...=\beta_k=0 \\
H_1: \beta_1,\beta_2,...,\beta_k至少有一个不等于0
$$

第2步: 计算检验的统计量

$$
F = \frac{SSR/k}{SSE/(n-k-1)} \sim F(k,n-k-1)
$$

第3步：作出统计决策。
- 给定显著性水平$\alpha$，根据分子自由度$=k$,分母自由度$=n-k-1$查$F$分布表得到$F$。若$F>F_{\alpha}$则拒绝原假设；若$F<F_{\alpha}$则不拒绝原假设。
- 也可直接利用P值作出决策：若$P<\alpha$，则拒绝原假设；若$P>\alpha$,则不拒绝原假设。




## 回归系数检验和推断

回归系数检验的具体步骤如下：

第1步：提出假设。对于任意参数$\beta_i(i=1,2,...,k)$,有

$$
H_0: \beta_i = 0; H_1: \beta_i \neq 0
$$

第2步：计算检验的统计量$t$。

$$
t_i = \frac{\hat{\beta}_i}{S_{\hat{\beta}_i}} \sim t(n-k-1)
$$

其中,$S_{\hat{\beta}_i}$是回归系数$\hat{\beta}_i$的抽样分布的标准差, 即

$$
S_{\hat{\beta}_i} = \frac{S_e}{\sqrt{\sum x_i^2 - \frac{1}{n}(\sum x_i)^2}}
$$

第3步：作出统计决策。给定显著性水平$\alpha$，根据自由度$=n一k一1$查$t$分布表，得到
$t_{\alpha/2}$的值。若$|t|>t_{\alpha/2}$,则拒绝原假设；若$|t|<t_{\alpha/2}$则不拒绝原假设。



## 参考
- 统计学第8版250页