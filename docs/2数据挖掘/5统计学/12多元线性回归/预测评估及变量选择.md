# 预测评估及变量选择

### 拟合精度与预测精度
拟合精度: 模型与已知数据的契合度
预测精度: 模型与未知数据的契合度

### 过拟合
过拟合: 拟合精度很高, 预测精度却很低的现象叫做过拟合

### 变量选择的意义
解释变量过多是过拟合的常见原因. 删除多余的解释变量有可能提高预测精确度, 而增加多余的解释变量会提高拟合精度.


### 泛化误差
预测值和未知数据之间的误差叫做泛化误差.

### 训练集和测试集
用来估计参数的数据叫做训练集.
通过评估训练集的拟合程度可以求出拟合精度, 但不能评估泛化误差.
在估计参数时特意保留的一部分已知数据叫做测试集.
使用测试集评估模型进度可以在一定程度上评估泛化误差.

### 交叉验证
基于特定的准则把数据分为训练集和测试集, 针对测试集评价模型预测精度的方法叫做交叉验证法(cross validation, cv).
交叉验证法主要有留出交叉验证(leave-p-out cv)和k折交叉验证(k-fold cv)两种.
1. 留出交叉验证
从已知数据中取出p个数据作为测试集. 例如, 留2交叉验证就是从已知数据中取出2个数据用来评估预测精度, 将其余数据作为训练集. 通过这种方法计算所有可能的数据组合的预测精度, 得出的结果的均值就是最终的评估值.
2. k折交叉验证
把已知数据分为K组, 取其中1组作为测试集. 重复K次, 以预测精度的均值作为最终的评估值

假设样本容量为100, 当留出交叉验证是留出1个数据, K折交叉验证是分为100组时, 测试数据其实都是1个数据, 因此两种验证方法等价.

交叉验证的缺点是要反复进行参数估计和精度评估, 计算量巨大.

### 赤池信息量准则
赤池信息量准则(AIC)的数学公式如下:
$$
AIC = -2 \times (最大对数似然 - 参与估计的参数个数)
$$
AIC越小, 模型越合适.
对数似然越大, 拟合精度就越高. 但如果过于注重拟合精度, 泛化误差就会变大.
在AIC中, 参数个数为惩罚指标.
解释变量越多, 对数似然越大, 同时惩罚也越严重. AIC可以判断增加的对数似然能否弥补更多的解释变量带来的缺点.
可以使用AIC删除多余的变量.
比起交叉验证法, AIC的一大优势是计算量更小.



参考:
