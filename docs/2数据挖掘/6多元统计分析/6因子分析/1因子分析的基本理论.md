# 因子分析的基本理论

因子分析(factor analysis)模型是主成分分析的推广。它也是利用降维的思想，由研究原始变量相关矩阵内部的依赖关系出发，把一些具有错综复杂关系的变量归结为少数几个综合因子的一种多变量统计分析方法。相比主成分分析，因子分析更倾向于描述原始变量之间的相关关系，因此，因子分析的出发点是原始变量的相关矩阵。因子分析的思想始于I904年查尔斯·斯皮尔曼(Charles Spearman)对学生考试成绩的研究。

## 因子分析的基本思想


因子分析的基本思想是根据相关性大小把原始变量分组，使得同组内的变量之间相关性较高，而不同组的变量间的相关性则较低。每组变量代表一个基本结构，并用一个不可观测的综合变量表示，这个基本结构就称为`公共因子`。对于所研究的某一具体问题，原始变量可以分解成两部分之和的形式，一部分是少数几个不可测的所谓`公共因子的线性函数`，另一部分是`与公共因子无关的特殊因子`。

某一类商品中很多商品的价格之间存在明显的相关性或相互依赖性，只要选择几种主要商品的价格，进而对这几种主要商品的价格进行综合，得到某一种假想的“综合商品”的价格，就足以反映某一类物价的变动情况，这里，“综合商品”的价格就是提取出来的因子。这样，对各类商品物价或仅对主要类别商品的物价进行类似分析然后加以综合，就可以反映出物价的整体变动情况。


## 因子分析的基本理论及模型
查尔斯·斯皮尔曼1904年用到的例子。斯皮尔曼在该例中研究了33名学生古典语(C)、法语(F)、英语(E)、数学(M)、判别(D)和音乐(Mu)6门考试成绩之间的相关性，并得到如下相关矩阵：

--|C|F|E|M|D|Mu
--|--|--|--|--|--|--
C|1.00|0.83|0.78|0.70|0.66|0.63
F|0.83|1.00|0.67|0.67|0.65|0.57
E|0.78|0.67|1.00|0.64|0.54|0.51
M|0.70|0.67|0.64|1.00|0.45|0.51
D|0.66|0.65|0.54|0.45|1.00|0.40
Mu|0.63|0.57|0.51|0.51|0.40|1.00

斯皮尔曼注意到上面相关矩阵中一个有趣的规律，即如果不考虑对角元素的话，任意两列的元素大致成比例，对C列和E列有:

$$
\frac{0.83(FC)}{0.67(FE)} \approx \frac{0.70(MC)}{0.64(ME)} \approx \frac{0.66(DC)}{0.54(DE)} \approx \frac{0.63(MuC)}{0.51(MuE)} \approx 1.2
$$

于是斯皮尔曼指出每一科目的考试成绩都遵从以下形式：
$$
X_i = a_i F + e_i
$$

式中, $X_i$为第$i$门科目标准化后的考试成绩, 均值为0, 方差为1;F为公共因子，对各科考试成绩均有影响，也是均值为0，方差为1; $e_i$为仅对第$i$门科目考试成绩有影响的特殊因子，F与$e_i$相互独立。也就是说，每一门科目的考试成绩都可以看作一个公共因子（可以认为是一般智力）与一个特殊因子的和。在满足以上假定的条件下，就有:
$$
cov(X_i, X_j) = E[(a_i F + e_i)(a_j F + e_j)] = a_i a_j var(F) = a_i a_j
$$
于是有:
$$
\frac{cov(X_i, X_j)}{cov(X_i, X_j)} = \frac{a_j}{a_k}
$$

上式, 与$i$无关(除式约去$a_i$), 与在相关矩阵中所观察到的比例关系相一致.

此外, 还可以得到有关$X_i$方差的关系式:
$$
var(X_i) = var(a_i F + e_i) = var(a_i F) + var(e_i) = a_i^2 var(F) + var(e_i)\\
 = a_i^2 + var(e_i)

$$

因为$a_i$是一个常数, F与$e_i$相互独立，且F与$X_i$的方差均被假定为1，于是有
$$
1 = a_i^2 + var(e_i)
$$

因此，常数$a_i$的意义就在于其平方表示了公共因子F解释$X_i$方差的比例，因此称为因子载荷，而$a_i^2$称为共同度。

对斯皮尔曼的例子进行推广，假定每一门科目的考试成绩都受到个公共因子的影响及一个特殊因子的影响，于是就变成了如下因子分析模型的一般形式：
$$
X_i = a_{i1} F_1 + a_{i2} F_2 + ... + a_{im}F_m  + e_i
$$

式中，$X_i$为标准化后的第$i$门科目的考试成绩，均值为0，方差为1;$F_1, F_2, ..., F_m$是彼此独立的公共因子，都满足均值为0，方差为1；$e_i$为特殊因子，与每一个公共因子均不相关且均值为0;$a_{i1}, a_{i2}, ...,a_{im}$为对第$i$门科目考试成绩的因子载荷。对该模型，有

$$
var(X_i) = a_{i1}^2 + a_{i2}^2 + ... + a_{im}^2 + var(e_i) = 1
$$

式中，$a_{i1}^2 + a_{i2}^2 + ... + a_{im}^2$表示公共因子解释$X_i$方差的比例，称为$X_i$的共同度；相对的，$var(e_i)$可称为$X_i$的特殊度或剩余方差，表示$X_i$的方差中与公共因子无关的
部分。因为共同度不会大于1，因此，$一1≤a_{ij}≤1$。还可以很容易地得到如下X:与X,相关系数的关系式：
$$
r_{ij} = a_{i1}a_{j1} + a_{i2}a_{j2} + ... + a_{im}a_{jm}
$$

所以当$X_i$与$X_j$,在某一公共因子上的载荷均较大时，也就表明了$X_i$与$X_j$,的相关性较强。

总结因子分解的一般模型:
$$
\begin{align*}
& X_1 = a_{11} F_1 + a_{12} F_2 + ... + a_{1m} F_m + \epsilon_1 \\
& X_2 = a_{21} F_1 + a_{22} F_2 + ... + a_{2m} F_m + \epsilon_2 \\
& ... \\
& X_p = a_{p1} F_1 + a_{p2} F_2 + ... + a_{pm} F_m + \epsilon_p \\
\end{align*}
$$

矩阵形式可以表示为
$$
X = AF + \epsilon =

\begin{pmatrix}
    a_{11} & a_{12} & ... & a_{1m} \\
    a_{21} & a_{22} & ... & a_{2m} \\
    ...    & ...    & ... & ...    \\
    a_{p1} & a_{p2} & ... & a_{pm} \\
\end{pmatrix}

\begin{pmatrix}
    F_1 \\
    F_2 \\
    ... \\
    F_m
\end{pmatrix}

+

\begin{pmatrix}
    \epsilon_1 \\
    \epsilon_2 \\
    ... \\
    \epsilon_p
\end{pmatrix}
$$

上式中, 公共因子$F_1,F_2,...,F_m$相互独立且不可测，是在原始变量的表达式中都出现的因子。公共因子的含义必须结合实际问题的具体意义确定。$\epsilon_1,\epsilon_2,...,\epsilon_p$叫做特殊因子，是向量$X$的分量$X_i(i=1,2,...,p)$所特有的因子。各特殊因子之间以及特殊因子与所有公共因子之间也都是相互独立的。矩阵$A$中的元素$a_{ij}$称为因子载荷，$a_{ij}$的绝对值越大($|a_{ij}|≤1$),表明$X_i$:与$F_j$的相依程度越大，或称公共因子$F_j$对于$X_i$的载荷量越大，进行因子分析的目的之一就是要求出各个因子载荷的值。

经过后面的分析会看到，因子载荷的概念与上一章主成分分析中的因子负荷量相对等，实际上，由于因子分析与主成分分析非常类似，若把$\epsilon_i$看做$a_{i,m+1} F_{m+1} + a_{i,m+2} F_{m+2} + ... + a_{i,p} F_p$的综合作用，则除了此处的因子为不可测变量这一区别，因子载荷与主成分分析中的因子负荷量是一致的。很多人对这两个概念并不加以区分而都称作因子载荷。矩阵$A$称为因子载荷矩阵。


载荷矩阵A的统计意义以及公共因子与原始变量之间的关系: 
(1)因子载荷a,的统计意义。

$$
cov(X_i, F_i) = cov(\sum_{j=1}^m a_{ij} F_j + \epsilon_i,F_j) \\
= cov(\sum_{j=1}^m a_{ij} F_j, F_j) + cov(\epsilon_i, F_j) \\
= a_{ij}
$$

即$a_{ij}$是$X_i$与$F_j$的协方差，而注意到$X_i$与$F_j(i=1,2,...,p;j=1,2,...,
m)$都是均值为0，方差为1的变量，因此，$a_{ij}$同时也是$X_i$与$F_j$的相关系数。对比主成分分析一章有关因子负荷量的论述并对两者进行比较。

(2)变量共同度与剩余方差。在上面斯皮尔曼的例子中我们提到了共同度与剩
余方差的概念，我们重新总结这两个概念如下：

称$a_{i1}^2 + a_{i2}^2 + ... + a_{im}^2$为变量$X_i$的共同度，记为$h_i^2(i=1,2,...,p)$。由因子分析模型的假设前提，易得
$$
var(X_i) = 1 = h_i^2 + var(\epsilon_i)
$$

记$var(\epsilon_i)=\sigma_i^2$, 则
$$
var(X_i) = 1 + h_i^2 + \sigma_i^2
$$

上式表明共同度$h_i^2$与剩余方差$\sigma_i^2$有互补的关系，$h_i^2$越大，表明$X_i$对公共因子的依赖程度越大，公共因子能解释$X_i$方差的比例越大，因子分析的效果也就越好。


(3)公共因子$F_j$的方差贡献。共同度考虑的是所有公共因子$F_1,F_2,...,F_m$与某一个原始变量的关系，与此类似，考虑某一个公共因子$F_j$,与所有原始变量$X_1,X_2,...,X_p$的关系。

记$g_j^2=a_{1j}^2 + a_{2j}^2 + ... + a_{pj}^2(j=1,2,...,m)$,则$g_j^2$表示的是公共因子$F_j$,对于X的每一分量$X_i(i=1,2,...,p)$所提供的方差的总和，称为公共因子$F_j$对原始变量向量$X$的方差贡献，它是衡量公共因子相对重要性的指标。$g_j^2$越大，表明公共因子$F_j$,对$X$的贡献越大，或者说对$X$的影响和作用就越大。如果将因子载荷矩阵$A$的所有$g_j^2(j=1,2,...,m)$都计算出来，并按其大小排序，就可以依此提炼出最有影响的公共因子。

## 因子载荷的求解
因子分析可以分为确定因子载荷、因子旋转及计算因子得分三个步骤。首要的步骤即为确定因子载荷或者根据样本数据确定因子载荷矩阵A。有很多方法可以完成这项工作，如主成分法、主轴因子法、最小二乘法、极大似然法、$α$因子提取法等。这些方法求解因子载荷的出发点不同，所得的结果也不完全相同。下面介绍主成分分析法:

用主成分法确定因子载荷是在进行因子分析之前先对数据进行一次主成分分析，然后把前几个主成分作为未旋转的公共因子。相对于其他确定因子载荷的方法而言，主成分法比较简单。但是，由于用这种方法所得的特殊因子$\epsilon_1, \epsilon_2, ..., \epsilon_p$之间并不相互独立，因此，用主成分法确定因子载荷不完全符合因子模型的假设前提，也就是说所得的因子载荷并不完全正确。当共同度较大时，特殊因子所起的作用较小，特殊因子之间的相关性所带来的影响几乎可以忽略。事实上，很多有经验的分析人员在进行因子分析时，总是先用主成分法进行分析，然后再尝试其他的方法。

用主成分法寻找公共因子的方法如下：假定从相关阵出发求解主成分，设有$p$个变量，则可以找出$p$个主成分。将所得的p个主成分按由大到小的顺序排列，记为$Y_1,Y_2,...,Y_p$，则主成分与原始变量之间存在如下关系式：
$$
\begin{align*}
& Y_1 = \gamma_{11} X_1 + \gamma_{12} X_2 + ... + \gamma_{1p} X_p \\
& Y_2 = \gamma_{21} X_1 + \gamma_{22} X_2 + ... + \gamma_{2p} X_p \\
& ... \\
& Y_p = \gamma_{p1} X_1 + \gamma_{p2} X_2 + ... + \gamma_{pp} X_p \\
\end{align*}
$$

式中, $\gamma_{ij}$为随机向量$X$的相关矩阵的特征根所对应的特征向量的分量，因为特征向量之间彼此正交，从$X$到$Y$的转换关系是可逆的，很容易得出由$Y$到$X$的转换关系为：

$$
\begin{align*}
& X_1 = \gamma_{11} Y_1 + \gamma_{21} Y_2 + ... + \gamma_{p1} Y_p \\
& X_2 = \gamma_{12} Y_1 + \gamma_{22} Y_2 + ... + \gamma_{p2} Y_p \\
& ... \\
& X_p = \gamma_{1p} Y_1 + \gamma_{2p} Y_2 + ... + \gamma_{pp} Y_p \\
\end{align*}
$$

对上面每一等式只保留前$m$个主成分而把后面的部分用$\epsilon_i$代替，则上式转化为：


$$
\begin{align*}
& X_1 = \gamma_{11} Y_1 + \gamma_{21} Y_2 + ... + \gamma_{m1} Y_m + \epsilon_1 \\
& X_2 = \gamma_{12} Y_1 + \gamma_{22} Y_2 + ... + \gamma_{m2} Y_m + \epsilon_2 \\
& ... \\
& X_p = \gamma_{1p} Y_1 + \gamma_{2p} Y_2 + ... + \gamma_{mp} Y_m + \epsilon_p \\
\end{align*}
$$

上式在形式上已经与因子模型相一致，并且$Y_i(i=1,2,...,m)$之间相互独立，$Y_i$与$\epsilon_i$之间相互独立。为了把$Y_i$转化成合适的公共因子，现
在要做的工作只是把主成分$Y_i$变成方差为1的变量。为完成此变换，必须将$Y_i$除
以其标准差，由上一章主成分分析的知识知其标准差即为特征根的平方根$\sqrt{\lambda_i}$。于
是，令$F_i = Y_i/\sqrt{\lambda_i},a_{ij}=\sqrt{\lambda_j} \gamma_{ji}$,则上式变为：

$$
\begin{align*}
& X_1 = a_{11} F_1 + a_{12} F_2 + ... + a_{1m} F_m + \epsilon_1 \\
& X_2 = a_{21} F_1 + a_{22} F_2 + ... + a_{2m} F_m + \epsilon_2 \\
& ... \\
& X_p = a_{p1} F_1 + a_{p2} F_2 + ... + a_{pm} F_m + \epsilon_p \\
\end{align*}
$$

这与因子模型完全一致，这样，就得到了载荷矩阵$A$和一组初始公共因子（未旋转）。

一般设入$\lambda_1, \lambda_2, ..., \lambda_p(\lambda_1 \geq \lambda_2 \geq ... \geq \lambda_p)$为样本相关阵R的特征根，$\gamma_1, \gamma_2, ..., \gamma_p$为对应的标准正交化特征向量。设$m < p$,则因子载荷矩阵$A$的一个解为：
$$
\hat{A} = (\sqrt{\lambda_1}\gamma_1, \sqrt{\lambda_2} \gamma_2, ..., \sqrt{\lambda_m} \gamma_m)
$$

共同度的估计未:
$$
\hat{h}_i^2 = \hat{a}_{i1}^2 + \hat{a}_{i2}^2 + ... + \hat{a}_{im}^2
$$


那么如何确定公共因子的数目$m$呢？一般而言，这取决于问题的研究者本人。对于同一问题进行因子分析时，不同的研究者可能会给出不同的公共因子数。当然，有时候由数据本身的特征可以很明确地确定因子数目。当用主成分法进行因子分析时，也可以借鉴确定主成分个数的准则，如所选取的公共因子的信息量的和达到总体信息量的一个合适比例为止。但对这些准则不应生搬硬套，应具体问题具体分析，总之要使所选取的公共因子能够合理地描述原始变量相关阵的结构，同时要有利于因子模型的解释。


## 因子旋转


不管用何种方法确定初始因子载荷矩阵$A$,它们都不是唯一的。设$F_1,F_2,...,F_m$是初始公共因子，则可以建立它们的如下线性组合得到新的一组公共因子$F_1',F_2',...,F_m'$,使得$F_1',F_2',...,F_m'$彼此相互独立，同时也能很好地解释原始变量之间的相关关系。


$$
\begin{align*}
& F_1' = d_{11} F_1 + d_{12} F_2 + ... + d_{1m} F_m \\
& F_2' = d_{21} F_1 + d_{22} F_2 + ... + d_{2m} F_m \\
& ... \\
& F_m' = d_{m1} F_1 + d_{m2} F_2 + ... + d_ {mm} F_m \\
\end{align*}
$$

这样的线性组合可以找到无数组，由此便引出了因子分析的第二个步骤一因子旋转。建立因子分析模型的目的不仅在于找到公共因子，更重要的是知道每一个公共因子的意义，以便对实际问题进行分析。然而，我们得到的初始因子解各主因子的典型代表变量不是很突出，容易使因子的意义含糊不清，不便于对实际问题进行分析。出于这种考虑，可以对初始公共因子进行线性组合，即进行因子旋转，以期找到意义更为明确、实际意义更明显的公共因子。经过旋转后，公共因子对$X_i$的贡献$h_i^2$并不改变，但由于载荷矩阵发生变化，公共因子本身就可能发生很大的变化，每一个公共因子对原始变量的贡献$g_i^2$不再与原来相同，经过适当的旋转，我们就可以得到比较令人满意的公共因子。


因子旋转分为正交旋转与斜交旋转。正交旋转由初始载荷矩阵$A$右乘一正交阵得到。经过正交旋转而得到的新的公共因子仍然保持彼此独立的性质。而斜交旋转则放弃了因子之间彼此独立这个限制，因而可能达到更为简洁的形式，其实际意义也更容易解释。但不论是正交旋转还是斜交旋转，都应当使新的因子载荷系数要么尽可能地接近于零，要么尽可能地远离零。因为一个接近于零的载荷$a_{ij}$，表明$X_i$与$F_j$的相关性很弱；而一个绝对值比较大的载荷$a_{ij}$则表明公共因子$F_j$在很大程度上解释了$X_i$的变化。这样，如果任一原始变量都与某些公共因子存在较强的相关关系，而与另外的公共因子几乎不相关的话，公共因子的实际意义就会比较容易确定。


## 因子得分

当因子模型建立之后，往往需要反过来考察每一个样品的性质及样品之间的相互关系。比如当关于企业经济效益的因子模型建立之后，我们希望知道每一个企业经济效益的优劣，或者把诸企业划分归类，如哪些企业经济效益较好，哪些企业经济效益一般，哪些企业经济效益较差等。这就需要进行因子分析的第三个步骤，即计算因子得分。顾名思义，因子得分就是公共因子F1,F2,…,Fm在每一个样品点上的得分。这需要我们给出公共因子用原始变量表示的线性表达式，这样的表达式一旦能够得到，就可以很方便地把原始变量的取值代入表达式中，求出各因子的得分值。
在上一章的分析中曾给出了主成分得分的概念，其意义和作用与因子得分相似。但是在此处，公共因子用原始变量线性表示的关系式并不易得到。在主成分分析中，主成分是原始变量的线性组合，当取p个主成分时，主成分与原始变量之间的变换关系是可逆的，只要知道了原始变量用主成分线性表示的表达式，就可以方便地得到用原始变量表示主成分的表达式；而在因子模型中，公共因子的个数少于原始变量的个数，且公共因子是不可观测的隐变量，载荷矩阵A不可逆，因而不能直接求得公共因子用原始变量表示的精确线性组合。解决该问题的一种方法是用回归的思想求出线性组合系数的估计值，即建立如下以公共因子为因变量、原始变量为自变量的回归方程：
$$
F_j = \beta_{j1}X_1 + \beta_{j2}X_2 + ... + \beta_{jp}X_p, j=1,2,...,m
$$

此处因为原始变量与公共因子变量均为标准化变量，所以回归模型中不存在常数项。在最小二乘意义下，可以得到$F$的估计值：
$$
\hat{F} = A'R^{-1}X
$$

式中，$A$为因子载荷矩阵；$R$为原始变量的相关阵；$X$为原始变量向量。这样，在得到一组样本值后，就可以代入上面的关系式求出公共因子的估计得分，从而用少数公共因子去描述原始变量的数据结构，用公共因子得分去描述原始变量的取值。在估计出公共因子得分后，可以利用因子得分进行进一步的分析，如样本点之间的比较分析，对样本点的聚类分析等。


## 主成分分析与因子分析的区别
(1)因子分析把展示在我们面前的诸多变量看成由对每一个变量都有作用的一些公共因子和一些仅对某一个变量有作用的特殊因子线性组合而成。因此，我们的目的就是要从数据中探查能对变量起解释作用的公共因子和特殊因子，以及公共因子和特殊因子组合系数。主成分分析则侧简单一些，它只是从空间生成的角度寻找能解释诸多变量绝大部分变异的几组彼此不相关的新变量（主成分）。
(2)因子分析中，把变量表示成各因子的线性组合，而主成分分析中，把主成分表示成各变量的线性组合。
(3)主成分分析中不需要有一些专门假设，因子分析则需要一些假设。因子分析的假设包括：各个公共因子之间不相关，特殊因子之间不相关，公共因子和特殊因子之间不相关。
(4)提取主因子的方法不仅有主成分法，还有极大似然法等，基于这些不同算法得到的结果一般也不同。而主成分只能用主成分法提取。
(5)主成分分析中，当给定的协方差矩阵或者相关矩阵的特征根唯一时，主成分一般是固定的；而因子分析中，因子不是固定的，可以旋转得到不同的因子。
(6)在因子分析中，因子个数需要分析者指定（SPSS根据一定的条件自动设定，只要是特征根大于1的因子都进人分析），随指定的因子数量不同而结果不同。在主成分分析中，主成分的数量是一定的，一般有几个变量就有几个主成分。
(7)和主成分分析相比，由于因子分析可以使用旋转技术帮助解释因子，在解释方面更加有优势。而如果想把现有的变量变成少数几个新的变量（新的变量几乎带有原来所有变量的信息）来进行后续的分析，则可以使用主成分分析。当然，这种情况也可以通过计算因子得分处理。所以，这种区分不是绝对的。


## 因子分析步骤
1. 选取原始变量
2. 求相关矩阵, 大多数相关系数大于0.3
3. 求公共因子及载荷矩阵
    - 主成分法
    - 极大似然法
    - 主轴因子法
4. 因子旋转
    - 正交旋转
    - 斜交旋转
5. 计算因子得分






## 参考
- [因子分析](https://www.nttcoms.com/service/research/dataanalysis/factor-analysis/)
- [因子分析とは](https://korekara-marketing.com/statistics-factor_analysis/)
- [因子分析](https://www.cnblogs.com/echo-coding/p/8724373.html)
- [因子分析法](https://wiki.mbalib.com/wiki/%E5%9B%A0%E5%AD%90%E5%88%86%E6%9E%90%E6%B3%95)
- [因子分析的基本思想](https://www.docin.com/p-2190177596.html)
- [如何通俗地解释因子分析](https://www.zhihu.com/question/40981105)
- 