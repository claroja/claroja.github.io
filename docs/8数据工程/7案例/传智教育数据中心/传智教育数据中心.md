# 传智教育数据中心

本案例基于Flink SQL 与Hudi整合，将MySQL数据库业务数据，实时采集存储到Hudi表中，使用Presto和Flink SQL分别进行离线查询分析和流式查询数据，最后报表存储到MySQL数据库，使用FineBI整合进行可视化展示。



![alt text](传智教育数据中心/传智教育数据中心架构.png)

1、MySQL数据库：
    传智教育客户业务数据存储及离线实时分析报表结果存储，对接可视化FineBI工具展示。

2、Flink SQL 引擎
    使用Flink SQL中CDC实时采集MySQL数据库表数据到Hudi表，此外基于Flink SQL Connector整合Hudi与MySQL，数据存储和查询。

3、Apache Hudi：数据湖框架
    传智教育业务数据，最终存储到Hudi表（底层存储：HDFS分布式文件系统），统一管理数据文件，后期与Spark和Hive集成，进行业务指标分析。
4、Presto 分析引擎
    一个Facebook开源的分布式SQL查询引擎，适用于交互式分析查询，数据量支持GB到PB字节。本案例中直接从Hudi表加载数据，其中依赖Hive MetaStore管理元数据。其中Presto可以集成多数据源，方便数据交互处理。

5、FineBI：报表工具
    帆软公司的一款商业图表工具, 让图表制作更加简单


## Flink CDC 实时数据采集



基于Flink CDC 实时采集数据，需要创建输入Input和输出Output两张表，编写INSERT...SELECT 插入查询语句。

![alt text](传智教育数据中心/实时数据采集.png)



1. 第一步、输入表InputTable
    ```sql
    create table tbl_customer_mysql (id STRING ...) WITH (
    'connector' = 'mysql-cdc',
    'hostname' = 'node1.itcast.cn',
    'port' = '3306',
    'username' = 'root',
    'password' = '123456',
    'server-time-zone' = 'Asia/Shanghai',
    'debezium.snapshot.mode' = 'initial',
    'database-name' = 'itcast_nev',
    'table-name' = 'customer'
    );
    ```

2. 第二步、输出表OutputTable
    ```sql
    CREATE TABLE edu_customer_hudi(...)
    PARTITIONED BY (part)
    WITH(
    'connector'='hudi',
    'path'= 'hdfs://node1.itcast.cn:8020/hudi-warehouse/edu_customer_hudi',
    'table.type'= 'MERGE_ON_READ',
    'hoodie.datasource.write.recordkey.field'= 'id',
    'write.precombine.field'= 'create_date_time',
    'write.tasks'= '1',
    'write.rate.limit'= '2000',
    'compaction.tasks'= '1',
    'compaction.async.enabled'= 'true',
    'compaction.trigger.strategy'= 'num_commits',
    'compaction.delta_commits'= '1',
    'changelog.enabled'= 'true'
    );
    ```

3. 第三步、插入查询语句

    ```sql
    insert into edu_customer_hudi
    select *, CAST(CURRENT_DATE AS STRING) AS part from tbl_customer_mysql;
    ```

    此时生成Flink job，提交到Standalone集群运行，首先将表中历史数据同步到Hudi表，再实时同步增量数据。


## Presto 即席查询


使用Presto 分析Hudi表数据，最终将结果直接存储到MySQL数据库表中，示意图如下。

![alt text](传智教育数据中心/Presto即席查询.png)

- 第一、Hive 中创建表，关联Hudi表
- 第二、Presto集成Hive，加载Hive表数据
- 第三、Presto集成MySQL，读取或者保存数据




## Flink SQL 流式分析

![alt text](传智教育数据中心/flinkSQL流式分析.png)

使用Flink SQL流式查询Hudi表今日实时数据，统计离线指标对应今日实时指标，最后使用FineBI实时大屏展示。

分析步骤
每个实时指标统计，分为三个步骤：

![alt text](传智教育数据中心/实时分析步骤.png)


第1步、创建输入表，流式加载Hudi表数据；
第2步、创建输出表，实时保存数据至MySQL表；
第3步、依据业务，编写SQL语句，查询输入表数据，并将结果插入输出表；


案例: 

实时流式统计：今日访问量，从Hudi表加载数据，Flink SQL统计，存储到MySQL表中


1. 首先创建输入表：流式加载，Hudi表数据
    
    ```sql
    CREATE TABLE edu_web_chat_ems_hudi (id string ...)
    PARTITIONED BY (part)
    WITH(
    'connector'='hudi',
    'path' = 'hdfs://node1.itcast.cn:8020/hudi-warehouse/edu_web_chat_ems_hudi',
    'table.type' = 'MERGE_ON_READ',
    'hoodie.datasource.write.recordkey.field' = 'id',
    'write.precombine.field' = 'create date_time',
    'read.streaming.enabled' = 'true',
    'read.streaming.check-interval' = '5',
    'read.tasks' = '1'
    );
    ```
2. 统计结果，存储至视图View：

    ```sql
    CREATE VIEW IF NOT EXISTS view_tmp_web_pv AS
    SELECT day_value, COUNT(id) AS total FROM (
    SELECT
        FROM_UNIXTIME(CAST(create_time AS BIGINT) / 1000, 'yyyy-MM-dd') AS day_value, id
    FROM edu_web_chat_ems_hudi
    WHERE part = CAST(CURRENT_DATE AS STRING)
    ) GROUP BY day_value;
    ```

3. 保存MySQL数据库：

    ```sql
    -- SQL Connector MySQL
    CREATE TABLE realtime_web_pv_mysql (
    report_date STRING,
    report_total BIGINT,
    PRIMARY KEY (report_date) NOT ENFORCED
    ) WITH (
    'connector' = 'jdbc',
    'url' = 'jdbc:mysql://node1.itcast.cn:3306/itcast_rpt',
    'driver' = 'com.mysql.cj.jdbc.Driver',
    'username' = 'root',
    'password' = '123456',
    'table-name' = 'realtime_web_pv'
    );

    -- INSERT INTO 插入
    INSERT INTO realtime_web_pv_mysql SELECT day_value, total FROM view_tmp_web_pv;
    ```





## FineBI 报表可视化


使用FineBI，连接数据MySQL数据库，加载业务指标报表数据，以不同图表展示。




